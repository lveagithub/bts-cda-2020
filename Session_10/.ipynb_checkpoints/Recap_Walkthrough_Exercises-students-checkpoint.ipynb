{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Walk-through Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NU2n6FVc_Esk"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods to be used later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"recap\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QfLLDXQP_Esj"
   },
   "source": [
    "#### Let's tackle the _digits dataset_ which is a simple MNIST-like dataset containing 1,797 grayscale 8Ã—8 images representing digits 0 to 9. \n",
    "#### We would first need to load the data and split it into test and training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5JIn9zWM_Esm"
   },
   "outputs": [],
   "source": [
    "X_digits, y_digits = load_digits(return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0Xml39Em_Eso"
   },
   "source": [
    "Let's split it into a training set and a test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BLWp3WAI_Ess"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "#X, y = make_moons(n_samples=500, noise=0.30, random_state=42)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "X_train, X_test, y_train, y_test  = train_test_split(X_digits, y_digits, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-eqklZvE_Esu"
   },
   "source": [
    "Now let's fit a Logistic Regression model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2719,
     "status": "ok",
     "timestamp": 1583753044454,
     "user": {
      "displayName": "Victor Francisco Pajuelo Madrigal",
      "photoUrl": "",
      "userId": "14873038234550459181"
     },
     "user_tz": -60
    },
    "id": "6Xa9CGUn_Esz",
    "outputId": "cba46bc3-834f-41ba-d368-3411fc1fb833"
   },
   "outputs": [],
   "source": [
    "log_reg = \\\n",
    "LogisticRegression(\n",
    "    multi_class='ovr',\n",
    "    solver='lbfgs',\n",
    "    max_iter=5000,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=5000, multi_class='ovr', random_state=42)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BNP55TA3kyDC"
   },
   "source": [
    "Now evaluate the Logistic Regression over the test set. You should get about 0.96 accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 711,
     "status": "ok",
     "timestamp": 1583753049270,
     "user": {
      "displayName": "Victor Francisco Pajuelo Madrigal",
      "photoUrl": "",
      "userId": "14873038234550459181"
     },
     "user_tz": -60
    },
    "id": "iTX7OWrl_Es5",
    "outputId": "4d70488f-8f09-4016-e707-b13a8d6bd8d7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9688888888888889"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GDGcqY7h_Es8"
   },
   "source": [
    "That accuracy will be our baseline to check the benefits of using clustering as a preprocessing step.\n",
    "\n",
    "Go ahead and **create a pipepline** that will:\n",
    "\n",
    "We will create a pipeline that will first cluster the training set into 50 \n",
    "\n",
    "1.   Cluster the training set into 50 clusters. Why 50? Well, we know we have 10 classes so it can be tempting to set $k=10$ but there are many digits that have different handwritting and we need to account for that. Running the K-Means will replace the images with their distances to those $k$ clusters.\n",
    "2.   Apply Logistic Regression model. Use the following setup:\n",
    "    * `multi_class=\"ovr\"`\n",
    "    * `solver=\"lbfgs\"`\n",
    "    * `max_iter=5000`\n",
    "    * `random_state=42`\n",
    "3. Fit the pipeline to `X_train` and `y_train`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9402,
     "status": "ok",
     "timestamp": 1583753161192,
     "user": {
      "displayName": "Victor Francisco Pajuelo Madrigal",
      "photoUrl": "",
      "userId": "14873038234550459181"
     },
     "user_tz": -60
    },
    "id": "8AncgW6w_Es_",
    "outputId": "aa08435f-2c4c-4622-b7fc-a2099fc2756a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('kmeans', KMeans(n_clusters=50, random_state=42)),\n",
       "                ('log_reg',\n",
       "                 LogisticRegression(max_iter=5000, multi_class='ovr',\n",
       "                                    random_state=42))])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline  = Pipeline ([\n",
    "    (\"kmeans\",KMeans(n_clusters=50, random_state =42)),\n",
    "    (\"log_reg\",LogisticRegression(\n",
    "        multi_class='ovr',\n",
    "        solver='lbfgs',\n",
    "        max_iter=5000,\n",
    "        random_state=42)),\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QOFPOG7Imlrb"
   },
   "source": [
    "Now print the pipeline score. Which accuracy did you get? You should get about 0.97"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 709,
     "status": "ok",
     "timestamp": 1583753165404,
     "user": {
      "displayName": "Victor Francisco Pajuelo Madrigal",
      "photoUrl": "",
      "userId": "14873038234550459181"
     },
     "user_tz": -60
    },
    "id": "7_2exdmc_EtD",
    "outputId": "bd26df01-a009-4b9d-8b97-8920ac8944c5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mVFhHNaTmzTR"
   },
   "source": [
    "Now calculate the reduction of the error rate, you can do this by...\n",
    "\n",
    "$1 - (1 - Pipeline Score) / (1 - Original Score)$\n",
    "\n",
    "You should get about a 28% reduction of error rate. That means going from 3% error to 2% error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1247,
     "status": "ok",
     "timestamp": 1583758822705,
     "user": {
      "displayName": "Victor Francisco Pajuelo Madrigal",
      "photoUrl": "",
      "userId": "14873038234550459181"
     },
     "user_tz": -60
    },
    "id": "qC50JfL0_EtF",
    "outputId": "3188d74f-042b-46c9-eb9e-dd24f5f3dec3"
   },
   "outputs": [],
   "source": [
    "1 - (1 - 0.98) / (1 - 0.968888)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R8Ta5Ad7_EtJ"
   },
   "source": [
    "Thats a very decent error rate reduction, just by passing a dataset to the classifier which has been clustered before. But we chose the number of clusters $k$ completely arbitrarily, we can surely do better. \n",
    "\n",
    "Since K-Means is just a preprocessing step in a classification pipeline, finding a good value for $k$ is much simpler than earlier: there's **no need to perform silhouette analysis** or **minimize the inertia**, the best value of $k$ is simply the one that results in the best classification performance during cross validation.\n",
    "\n",
    "How could we do that? You are right, by passing the pipeline through `GridSearchCV` (remember to call `GridSearchCV` and fit it to `X_train` and `y_train`). Also remember that we need to look for the number of clusters, so pass the `param_grid` values with a range of clusters from at least 2 to for instance 100.\n",
    "\n",
    "Hint, refer to the `n_clusters` parameter as `kmeans__n_clusters`. Beware!!!! This will take quite a bit, so run it and go for a coffee. Try it first in not so many clusters, so you can check that your code works. The life of a data scientist allows for many coffee breaks if automatization is done correctly :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 612
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 58213,
     "status": "ok",
     "timestamp": 1583730646408,
     "user": {
      "displayName": "Victor Francisco Pajuelo Madrigal",
      "photoUrl": "",
      "userId": "14873038234550459181"
     },
     "user_tz": -60
    },
    "id": "5L2LBGCC_EtM",
    "outputId": "be7f9b7d-8b39-48e7-9d1d-bdb5176e6982"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 98 candidates, totalling 294 fits\n",
      "[CV] kmeans__n_clusters=2 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............................. kmeans__n_clusters=2, total=   0.5s\n",
      "[CV] kmeans__n_clusters=2 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............................. kmeans__n_clusters=2, total=   0.5s\n",
      "[CV] kmeans__n_clusters=2 ............................................\n",
      "[CV] ............................. kmeans__n_clusters=2, total=   0.4s\n",
      "[CV] kmeans__n_clusters=3 ............................................\n",
      "[CV] ............................. kmeans__n_clusters=3, total=   0.4s\n",
      "[CV] kmeans__n_clusters=3 ............................................\n",
      "[CV] ............................. kmeans__n_clusters=3, total=   0.5s\n",
      "[CV] kmeans__n_clusters=3 ............................................\n",
      "[CV] ............................. kmeans__n_clusters=3, total=   0.4s\n",
      "[CV] kmeans__n_clusters=4 ............................................\n",
      "[CV] ............................. kmeans__n_clusters=4, total=   0.6s\n",
      "[CV] kmeans__n_clusters=4 ............................................\n",
      "[CV] ............................. kmeans__n_clusters=4, total=   0.5s\n",
      "[CV] kmeans__n_clusters=4 ............................................\n",
      "[CV] ............................. kmeans__n_clusters=4, total=   0.5s\n",
      "[CV] kmeans__n_clusters=5 ............................................\n",
      "[CV] ............................. kmeans__n_clusters=5, total=   0.5s\n",
      "[CV] kmeans__n_clusters=5 ............................................\n",
      "[CV] ............................. kmeans__n_clusters=5, total=   0.5s\n",
      "[CV] kmeans__n_clusters=5 ............................................\n",
      "[CV] ............................. kmeans__n_clusters=5, total=   0.5s\n",
      "[CV] kmeans__n_clusters=6 ............................................\n",
      "[CV] ............................. kmeans__n_clusters=6, total=   0.6s\n",
      "[CV] kmeans__n_clusters=6 ............................................\n",
      "[CV] ............................. kmeans__n_clusters=6, total=   0.6s\n",
      "[CV] kmeans__n_clusters=6 ............................................\n",
      "[CV] ............................. kmeans__n_clusters=6, total=   0.6s\n",
      "[CV] kmeans__n_clusters=7 ............................................\n",
      "[CV] ............................. kmeans__n_clusters=7, total=   0.8s\n",
      "[CV] kmeans__n_clusters=7 ............................................\n",
      "[CV] ............................. kmeans__n_clusters=7, total=   0.7s\n",
      "[CV] kmeans__n_clusters=7 ............................................\n",
      "[CV] ............................. kmeans__n_clusters=7, total=   0.7s\n",
      "[CV] kmeans__n_clusters=8 ............................................\n",
      "[CV] ............................. kmeans__n_clusters=8, total=   0.8s\n",
      "[CV] kmeans__n_clusters=8 ............................................\n",
      "[CV] ............................. kmeans__n_clusters=8, total=   0.8s\n",
      "[CV] kmeans__n_clusters=8 ............................................\n",
      "[CV] ............................. kmeans__n_clusters=8, total=   0.9s\n",
      "[CV] kmeans__n_clusters=9 ............................................\n",
      "[CV] ............................. kmeans__n_clusters=9, total=   1.0s\n",
      "[CV] kmeans__n_clusters=9 ............................................\n",
      "[CV] ............................. kmeans__n_clusters=9, total=   1.0s\n",
      "[CV] kmeans__n_clusters=9 ............................................\n",
      "[CV] ............................. kmeans__n_clusters=9, total=   1.1s\n",
      "[CV] kmeans__n_clusters=10 ...........................................\n",
      "[CV] ............................ kmeans__n_clusters=10, total=   1.4s\n",
      "[CV] kmeans__n_clusters=10 ...........................................\n",
      "[CV] ............................ kmeans__n_clusters=10, total=   1.4s\n",
      "[CV] kmeans__n_clusters=10 ...........................................\n",
      "[CV] ............................ kmeans__n_clusters=10, total=   1.3s\n",
      "[CV] kmeans__n_clusters=11 ...........................................\n",
      "[CV] ............................ kmeans__n_clusters=11, total=   1.5s\n",
      "[CV] kmeans__n_clusters=11 ...........................................\n",
      "[CV] ............................ kmeans__n_clusters=11, total=   1.4s\n",
      "[CV] kmeans__n_clusters=11 ...........................................\n",
      "[CV] ............................ kmeans__n_clusters=11, total=   1.6s\n",
      "[CV] kmeans__n_clusters=12 ...........................................\n",
      "[CV] ............................ kmeans__n_clusters=12, total=   1.8s\n",
      "[CV] kmeans__n_clusters=12 ...........................................\n",
      "[CV] ............................ kmeans__n_clusters=12, total=   2.0s\n",
      "[CV] kmeans__n_clusters=12 ...........................................\n",
      "[CV] ............................ kmeans__n_clusters=12, total=   2.1s\n",
      "[CV] kmeans__n_clusters=13 ...........................................\n",
      "[CV] ............................ kmeans__n_clusters=13, total=   2.1s\n",
      "[CV] kmeans__n_clusters=13 ...........................................\n",
      "[CV] ............................ kmeans__n_clusters=13, total=   2.2s\n",
      "[CV] kmeans__n_clusters=13 ...........................................\n",
      "[CV] ............................ kmeans__n_clusters=13, total=   2.4s\n",
      "[CV] kmeans__n_clusters=14 ...........................................\n",
      "[CV] ............................ kmeans__n_clusters=14, total=   2.6s\n",
      "[CV] kmeans__n_clusters=14 ...........................................\n",
      "[CV] ............................ kmeans__n_clusters=14, total=   2.8s\n",
      "[CV] kmeans__n_clusters=14 ...........................................\n",
      "[CV] ............................ kmeans__n_clusters=14, total=   2.5s\n",
      "[CV] kmeans__n_clusters=15 ...........................................\n",
      "[CV] ............................ kmeans__n_clusters=15, total=   2.8s\n",
      "[CV] kmeans__n_clusters=15 ...........................................\n",
      "[CV] ............................ kmeans__n_clusters=15, total=   4.1s\n",
      "[CV] kmeans__n_clusters=15 ...........................................\n",
      "[CV] ............................ kmeans__n_clusters=15, total=   2.9s\n",
      "[CV] kmeans__n_clusters=16 ...........................................\n",
      "[CV] ............................ kmeans__n_clusters=16, total=   3.2s\n",
      "[CV] kmeans__n_clusters=16 ...........................................\n",
      "[CV] ............................ kmeans__n_clusters=16, total=   3.2s\n",
      "[CV] kmeans__n_clusters=16 ...........................................\n",
      "[CV] ............................ kmeans__n_clusters=16, total=   3.3s\n",
      "[CV] kmeans__n_clusters=17 ...........................................\n",
      "[CV] ............................ kmeans__n_clusters=17, total=   4.1s\n",
      "[CV] kmeans__n_clusters=17 ...........................................\n",
      "[CV] ............................ kmeans__n_clusters=17, total=   3.2s\n",
      "[CV] kmeans__n_clusters=17 ...........................................\n",
      "[CV] ............................ kmeans__n_clusters=17, total=   3.6s\n",
      "[CV] kmeans__n_clusters=18 ...........................................\n",
      "[CV] ............................ kmeans__n_clusters=18, total=   4.0s\n",
      "[CV] kmeans__n_clusters=18 ...........................................\n",
      "[CV] ............................ kmeans__n_clusters=18, total=   3.2s\n",
      "[CV] kmeans__n_clusters=18 ...........................................\n",
      "[CV] ............................ kmeans__n_clusters=18, total=   3.6s\n",
      "[CV] kmeans__n_clusters=19 ...........................................\n",
      "[CV] ............................ kmeans__n_clusters=19, total=   3.7s\n",
      "[CV] kmeans__n_clusters=19 ...........................................\n",
      "[CV] ............................ kmeans__n_clusters=19, total=   3.1s\n",
      "[CV] kmeans__n_clusters=19 ...........................................\n",
      "[CV] ............................ kmeans__n_clusters=19, total=   3.6s\n",
      "[CV] kmeans__n_clusters=20 ...........................................\n",
      "[CV] ............................ kmeans__n_clusters=20, total=   3.5s\n",
      "[CV] kmeans__n_clusters=20 ...........................................\n",
      "[CV] ............................ kmeans__n_clusters=20, total=   3.9s\n",
      "[CV] kmeans__n_clusters=20 ...........................................\n",
      "[CV] ............................ kmeans__n_clusters=20, total=   3.6s\n",
      "[CV] kmeans__n_clusters=21 ...........................................\n",
      "[CV] ............................ kmeans__n_clusters=21, total=   5.1s\n",
      "[CV] kmeans__n_clusters=21 ...........................................\n",
      "[CV] ............................ kmeans__n_clusters=21, total=   6.0s\n",
      "[CV] kmeans__n_clusters=21 ...........................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............................ kmeans__n_clusters=21, total=   5.3s\n",
      "[CV] kmeans__n_clusters=22 ...........................................\n",
      "[CV] ............................ kmeans__n_clusters=22, total=   4.8s\n",
      "[CV] kmeans__n_clusters=22 ...........................................\n",
      "[CV] ............................ kmeans__n_clusters=22, total=   6.2s\n",
      "[CV] kmeans__n_clusters=22 ...........................................\n",
      "[CV] ............................ kmeans__n_clusters=22, total=   6.5s\n",
      "[CV] kmeans__n_clusters=23 ...........................................\n",
      "[CV] ............................ kmeans__n_clusters=23, total=   8.3s\n",
      "[CV] kmeans__n_clusters=23 ...........................................\n",
      "[CV] ............................ kmeans__n_clusters=23, total=   9.5s\n",
      "[CV] kmeans__n_clusters=23 ...........................................\n",
      "[CV] ............................ kmeans__n_clusters=23, total=   5.6s\n",
      "[CV] kmeans__n_clusters=24 ...........................................\n",
      "[CV] ............................ kmeans__n_clusters=24, total=   5.8s\n",
      "[CV] kmeans__n_clusters=24 ...........................................\n",
      "[CV] ............................ kmeans__n_clusters=24, total=  11.2s\n",
      "[CV] kmeans__n_clusters=24 ...........................................\n",
      "[CV] ............................ kmeans__n_clusters=24, total=  11.5s\n",
      "[CV] kmeans__n_clusters=25 ...........................................\n"
     ]
    }
   ],
   "source": [
    "# Doing 20 here now just to go faster in class\n",
    "param_grid = dict(kmeans__n_clusters=range(2, 100))\n",
    "\n",
    "grid_clf = GridSearchCV(pipeline,\n",
    "                       param_grid,\n",
    "                       cv=3,\n",
    "                       verbose=2,\n",
    "                       n_jobs=1)\n",
    "grid_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l1YG1CCpoVgT"
   },
   "source": [
    "Print the best parameters that we have defined (`kmeans__n_clusters`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 567,
     "status": "ok",
     "timestamp": 1583730689478,
     "user": {
      "displayName": "Victor Francisco Pajuelo Madrigal",
      "photoUrl": "",
      "userId": "14873038234550459181"
     },
     "user_tz": -60
    },
    "id": "ImkwGUCh_EtO",
    "outputId": "f05069b3-b738-4709-bc2b-345a931322ff"
   },
   "outputs": [],
   "source": [
    "# We will get bad scores here because we purposedly set the maximum number of clusters to 20\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TEAjnFHZpR5N"
   },
   "source": [
    "Print the resulting score of the GridSearchCV, you should get about 98 to 99% accuracy. And you should get that you got your best values with $k=99$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 656,
     "status": "ok",
     "timestamp": 1583730692191,
     "user": {
      "displayName": "Victor Francisco Pajuelo Madrigal",
      "photoUrl": "",
      "userId": "14873038234550459181"
     },
     "user_tz": -60
    },
    "id": "CJqsHaML_EtQ",
    "outputId": "c157c35d-6e1e-430e-9f75-6801705a4442"
   },
   "outputs": [],
   "source": [
    "# With 99 clusters we will get about 99%, but we only used  k=19\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering for Semi-supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ajiBN5a9_EtU"
   },
   "source": [
    "Another use case for clustering is in semi-supervised learning, when we have plenty of unlabeled instances and very few labeled instances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VHWQaSAG_EtV"
   },
   "source": [
    "Let's look at the performance of a logistic regression model when we only have 50 labeled instances. We can reduced the MNIST dataset loaded previously to just the last 50 instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wt6DYv32_EtW"
   },
   "outputs": [],
   "source": [
    "n_labeled = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 787,
     "status": "ok",
     "timestamp": 1583731882526,
     "user": {
      "displayName": "Victor Francisco Pajuelo Madrigal",
      "photoUrl": "",
      "userId": "14873038234550459181"
     },
     "user_tz": -60
    },
    "id": "UQtiXFIl_Eta",
    "outputId": "faaefbf2-7206-4756-b70b-ddf4af0d7d00"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7hMaZbKH_Etb"
   },
   "source": [
    "It's much less than earlier of course. Let's see how we can do better. First, let's cluster the training set into 50 clusters, then for each cluster let's find the image closest to the centroid. We will call these images the **representative** images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eLdM84Ni_Etc"
   },
   "outputs": [],
   "source": [
    "k = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OUSNQw9k_Ete"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9EVY1N3w_Eti"
   },
   "source": [
    "Now let's plot these representative images and label them manually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 157
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2683,
     "status": "ok",
     "timestamp": 1583732285062,
     "user": {
      "displayName": "Victor Francisco Pajuelo Madrigal",
      "photoUrl": "",
      "userId": "14873038234550459181"
     },
     "user_tz": -60
    },
    "id": "98VUppMm_Eti",
    "outputId": "aa89a744-74ca-4174-d8ae-0f15e194a519"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YBjAsipe_Etn"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# You will need to label here whatever appeared \n",
    "in your most representative images according to your random_state\n",
    "\"\"\"\n",
    "y_representative_digits = np.array([\n",
    "    2, 6, 0, 3, 4, 2, 8, 1, 7, 9,\n",
    "    5, 9, 8, 3, 6, 1, 8, 7, 2, 0,\n",
    "    4, 2, 9, 9, 5, 6, 7, 1, 6, 9,\n",
    "    4, 3, 1, 0, 8, 4, 7, 2, 5, 4,\n",
    "    5, 2, 2, 8, 5, 9, 2, 7, 7, 7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Above in the last row in position 5 is not an \"8\" is an \"1\"\n",
    "#y_train[representative_digit_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MM4Txx_g_Etp"
   },
   "source": [
    "Now we have a dataset of the most representative instances labeled. Unfortunately we only have 50 labeled instances, but instead of being completely random instances, each of them is a representative image of its cluster. Let's see if the performance is any better:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 702,
     "status": "ok",
     "timestamp": 1583732436006,
     "user": {
      "displayName": "Victor Francisco Pajuelo Madrigal",
      "photoUrl": "",
      "userId": "14873038234550459181"
     },
     "user_tz": -60
    },
    "id": "Vn7t54Gx_Etq",
    "outputId": "98dc4bb4-ce90-4d39-ea21-95b1cec3ea38"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yu0YiCuT_Ets"
   },
   "source": [
    "Wow! We jumped from accuracy although we are still only training the model on 50 instances. Since it's often costly and painful to label instances, especially when it has to be done manually by experts, it's a good idea to make them label representative instances rather than just random instances.\n",
    "\n",
    "So this is a very good technique to first take those most representative instances and label them, instead of labelling randomly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "APY00PGQ_Ets"
   },
   "source": [
    "But perhaps we can go one step further: what if we propagated the labels to all the other instances in the same cluster?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CT4QWKeq_Ets"
   },
   "outputs": [],
   "source": [
    "# Create an empty matrix with the length of X_train\n",
    "y_train_propagated = np.empty(len(X_train),\n",
    "                              dtype=np.int32)\n",
    "\n",
    "\"\"\"\n",
    "Propagate the cluster instances into that matrix by propagating the representative\n",
    "digit value to the full cluster that has that value\n",
    "\"\"\"\n",
    "for i in range(k):\n",
    "    y_train_propagated[kmeans.labels_==i] = y_representative_digits[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2819,
     "status": "ok",
     "timestamp": 1583732446244,
     "user": {
      "displayName": "Victor Francisco Pajuelo Madrigal",
      "photoUrl": "",
      "userId": "14873038234550459181"
     },
     "user_tz": -60
    },
    "id": "Cf7CilGj_Etw",
    "outputId": "cea459ba-2abc-4dcc-9e85-e7ed467bcbf5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1299,
     "status": "ok",
     "timestamp": 1583732446245,
     "user": {
      "displayName": "Victor Francisco Pajuelo Madrigal",
      "photoUrl": "",
      "userId": "14873038234550459181"
     },
     "user_tz": -60
    },
    "id": "nYRX2r4H_Ety",
    "outputId": "fd638a61-cc6b-4be7-ba7e-b579bbaa8d4c"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zb9QuOo6_Et1"
   },
   "source": [
    "We got a tiny little accuracy boost. Better than nothing, but we should probably have propagated the labels only to the instances closest to the centroid, because by propagating to the full cluster, we have certainly included some outliers. This might lead to a lot of problems, such as overfitting. Let's only propagate the labels to the 30th percentile closest to the centroid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fSd6yUJo_Et2"
   },
   "outputs": [],
   "source": [
    "percentile_closest = 30\n",
    "\n",
    "# Create an empty matrix with the length of X_train\n",
    "X_cluster_dist = X_digits_dist[np.arange(len(X_train)),\n",
    "                               kmeans.labels_]\n",
    "\n",
    "for i in range(k):\n",
    "    # Get the clusters that has the i value\n",
    "    in_cluster = (kmeans.labels_ == i)\n",
    "\n",
    "    # Index the newly created X_cluster_dist with in_cluster\n",
    "    cluster_dist = X_cluster_dist[in_cluster]\n",
    "\n",
    "    # Set up the percentile distance by using np.percentile\n",
    "    cutoff_distance = np.percentile(cluster_dist,\n",
    "                                    percentile_closest)\n",
    "\n",
    "    # Set a value to be above the cluster distance\n",
    "    above_cutoff = (X_cluster_dist > cutoff_distance)\n",
    "\n",
    "    # Set X_cluster_dist values to -1 when those are above cutoff distance\n",
    "    X_cluster_dist[in_cluster & above_cutoff] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X27psAfn_Et4"
   },
   "outputs": [],
   "source": [
    "# Get the real propagated values (not -1)\n",
    "partially_propagated = (X_cluster_dist != -1)\n",
    "\n",
    "# Index those values to X_train\n",
    "X_train_partially_propagated = X_train[partially_propagated]\n",
    "\n",
    "# Index those values to y_train\n",
    "y_train_partially_propagated = y_train_propagated[partially_propagated]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1292,
     "status": "ok",
     "timestamp": 1583732616334,
     "user": {
      "displayName": "Victor Francisco Pajuelo Madrigal",
      "photoUrl": "",
      "userId": "14873038234550459181"
     },
     "user_tz": -60
    },
    "id": "muqIdqiW_Et6",
    "outputId": "4305c6df-f310-48a5-9f04-4a95896a1fc1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 559,
     "status": "ok",
     "timestamp": 1583732616335,
     "user": {
      "displayName": "Victor Francisco Pajuelo Madrigal",
      "photoUrl": "",
      "userId": "14873038234550459181"
     },
     "user_tz": -60
    },
    "id": "Q335se1Y_Et7",
    "outputId": "278e3742-91a6-4c75-b605-689b37dfac0e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mtW-PVtR_Et_"
   },
   "source": [
    "Nice! With just 50 labeled instances (just 5 examples per class on average!), we got this performance, which is pretty close to the performance of logistic regression on the fully labeled _digits_ dataset. We got a bit lower performance but results should be more stable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "udLCmGFi_EuA"
   },
   "source": [
    "This is because the propagated labels are actually pretty good: their accuracy is very close to 99%:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 581,
     "status": "ok",
     "timestamp": 1583732645256,
     "user": {
      "displayName": "Victor Francisco Pajuelo Madrigal",
      "photoUrl": "",
      "userId": "14873038234550459181"
     },
     "user_tz": -60
    },
    "id": "k5iqzMar_EuA",
    "outputId": "c99eb851-d47a-4873-a387-3eb93bf99e7d"
   },
   "outputs": [],
   "source": [
    "np.mean(y_train_partially_propagated == y_train[partially_propagated])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
